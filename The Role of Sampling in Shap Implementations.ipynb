{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does SHAP work?\n",
    "\n",
    "This notebook explores the approach to feature sampling employed in the popular [`shap` python library](https://github.com/slundberg/shap). While the library [and its accompanying NeurIPS paper](http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions) are a focal point of the notebook, any promising / insightful directions in the ML, statistics, or game theory literature will be pursued."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup\n",
    "\n",
    "Load necessary python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from itertools import combinations, chain\n",
    "from scipy import stats\n",
    "from scipy.special import factorial, binom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Background\n",
    "\n",
    "## 1.a. Shapley Values\n",
    "\n",
    "Shapley values have their origins in game theory (Shapley 1953). The basic idea is:\n",
    "1. $n$ people can play a game\n",
    "2. I observe the outcomes of all $2^n$ subsets of those $n$ people playing the game\n",
    "\n",
    "If all I have is \\#2 above, can I deduce the value that a specific person contributes on average?\n",
    "\n",
    "To make this less theoretical, let's consider a simple example. I have 5 people doing a pushup challenge. Let's say they can each do the following amount of pushups in a minute:\n",
    "1. 100\n",
    "2. 60\n",
    "3. 40\n",
    "4. 30\n",
    "5. 10\n",
    "\n",
    "But all I observe is:\n",
    "* If 1, 2, 3, 4, and 5 all do the challenge, they do 240 total pushups\n",
    "* If 1, 2, and 4 do the challenge, they do 190 pushups\n",
    "* If 1 and 3 do the challenge, they do 140 pushups\n",
    "\n",
    "... and so on for every possible grouping ...\n",
    "\n",
    "The Shapley value is a formula for backing out an individual's contribution given the observed data:\n",
    "\n",
    "$\\phi_i(x) = \\sum_{S \\subseteq N} \\gamma_S (\\nu(S) - \\nu(S-i))$\n",
    "\n",
    "In words, \n",
    "* $i$ is the player whose contribution we're interested in\n",
    "* $S$ is some subset of players\n",
    "* $\\nu(S)$ is the outcome when this subset plays the game\n",
    "* $\\gamma_S$ is a combinatorial weight applied to each subset ($(s-1)!(n-s)!/n!$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's generate the \"observed\" data from the \"true\" Shapley values so we can see that the Shapley formula recovers the right values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = np.array([100, 60, 40, 30, 10])\n",
    "n = len(shap_values)\n",
    "shap_indices = np.arange(n)\n",
    "combination_iterator = list(chain.from_iterable(combinations(shap_indices, i) for i in range(n+1)))\n",
    "value_combinations = np.array([np.sum(shap_values[np.in1d(shap_indices, np.array(comb))]) for comb in combination_iterator])\n",
    "boolean_matrix = np.array([np.in1d(shap_indices, np.array(comb)) for comb in combination_iterator])*1\n",
    "my_list = ['Player {:d}'.format(i) for i in range(n)]; my_list.append(\"value\")\n",
    "observed_data = pd.DataFrame(np.concatenate([boolean_matrix, value_combinations.reshape(-1, 1)], axis=1), columns=my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player 0</th>\n",
       "      <th>Player 1</th>\n",
       "      <th>Player 2</th>\n",
       "      <th>Player 3</th>\n",
       "      <th>Player 4</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Player 0  Player 1  Player 2  Player 3  Player 4  value\n",
       "0          0         0         0         0         0      0\n",
       "1          1         0         0         0         0    100\n",
       "2          0         1         0         0         0     60\n",
       "3          0         0         1         0         0     40\n",
       "4          0         0         0         1         0     30\n",
       "5          0         0         0         0         1     10\n",
       "6          1         1         0         0         0    160\n",
       "7          1         0         1         0         0    140\n",
       "8          1         0         0         1         0    130\n",
       "9          1         0         0         0         1    110\n",
       "10         0         1         1         0         0    100\n",
       "11         0         1         0         1         0     90\n",
       "12         0         1         0         0         1     70\n",
       "13         0         0         1         1         0     70\n",
       "14         0         0         1         0         1     50\n",
       "15         0         0         0         1         1     40\n",
       "16         1         1         1         0         0    200\n",
       "17         1         1         0         1         0    190\n",
       "18         1         1         0         0         1    170\n",
       "19         1         0         1         1         0    170\n",
       "20         1         0         1         0         1    150\n",
       "21         1         0         0         1         1    140\n",
       "22         0         1         1         1         0    130\n",
       "23         0         1         1         0         1    110\n",
       "24         0         1         0         1         1    100\n",
       "25         0         0         1         1         1     80\n",
       "26         1         1         1         1         0    230\n",
       "27         1         1         1         0         1    210\n",
       "28         1         1         0         1         1    200\n",
       "29         1         0         1         1         1    180\n",
       "30         0         1         1         1         1    140\n",
       "31         1         1         1         1         1    240"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_minus(row, item):\n",
    "    temp = row.copy(); temp[item] = 0\n",
    "    return temp\n",
    "\n",
    "def row_equality(row, search_array):\n",
    "    return np.array_equal(row, search_array)\n",
    "\n",
    "def row_diff(matrix_row, df, boolean_matrix, item):\n",
    "    return (df.loc[np.apply_along_axis(row_equality, 1, boolean_matrix, matrix_row), \"value\"].values - \n",
    "            df.loc[np.apply_along_axis(row_equality, 1, boolean_matrix, set_minus(matrix_row, item)), \"value\"].values)\n",
    "\n",
    "def shap_difference(boolean_matrix, observed_data, item):\n",
    "    return np.apply_along_axis(row_diff, 1, boolean_matrix, df=observed_data, boolean_matrix=boolean_matrix, item=item)\n",
    "\n",
    "def shap_weight(s, n):\n",
    "    return (factorial(s-1)*factorial(n-s))/factorial(n)\n",
    "\n",
    "def compute_shap(player_num, boolean_matrix, observed_data, n):\n",
    "    return np.sum(shap_difference(boolean_matrix, observed_data, player_num).reshape(-1)*shap_weight(s=np.sum(boolean_matrix, axis=1), n = n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute Shapley values for each of the players in our game and see if they compare favorably to what we know to be the correct answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1 Shapley value: 100.00\n",
      "Player 2 Shapley value: 60.00\n",
      "Player 3 Shapley value: 40.00\n",
      "Player 4 Shapley value: 30.00\n",
      "Player 5 Shapley value: 10.00\n"
     ]
    }
   ],
   "source": [
    "for player in shap_indices:\n",
    "    shap_val = compute_shap(player, boolean_matrix, observed_data, n)\n",
    "    print(\"Player {:d} Shapley value: {:.2f}\".format(player+1, shap_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it works as advertised (though this was a pretty easy example).\n",
    "\n",
    "Now, the way Shapley values work as a regression explanation method, it would be intractable to do what we just did above. We can't iterate over $2^n$ combinations of features when the feature set is large. (For 15 features this would be 33k combinations.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b. Shap library deep dive\n",
    "\n",
    "How does the sampling in `shap` work? There are a few approaches, mostly designed to explain individual predictions. \n",
    "\n",
    "For the most general version of SHAP (the \"Kernel Explainer\"), the underlying code is [here](https://github.com/slundberg/shap/blob/master/shap/explainers/kernel.py#L322)\\[1\\]. \n",
    "\n",
    "At a high level, it's doing the following:\n",
    "\n",
    "1. Take user input on:\n",
    "    1. A data point to be explained (`explanation_data`)\n",
    "    2. A dataset of \"background\" or reference values for comparison (`background_data`)\n",
    "    3. The number of samples to generate (`n_samples`)\n",
    "2. Narrow down to the features that vary between the background dataset and the prediction of interest (i.e. if a dataset is full of people for whom `city=SF`, don't try to manipulate the `city` feature and attribute prediction changes to it). Call this value $M$.\n",
    "3. Letting $x$ be the number of features to modify in given sample, iterate over all $x$ from 1 to $M$:\n",
    "    1. For each of the $M \\choose x$ combinations of $x$ features:\n",
    "        1. Switch the values of the $x$ selected features in the background dataset to their values in the `explanation_data`\n",
    "        2. Add a corresponding sample with the opposite set of columns flipped (for example, if step 1 was to flip columns 1, 2, and 4, step 2 would be to flip columns 3 and 5)\n",
    "        3. Once you can no longer iterate through combinations without hitting the `n_samples` limit, take random samples of features to round out the number of sampled data points to `n_samples` exactly\n",
    "4. Run weighted least squares regression with kernel weights based on the number of features \"flipped\" (i.e. if all but one of the features is the same between the background sample and the synthetic sample, the weight is smaller as the synthetic sample is \"closer\" to the original data point)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the `SHAP` approach will return values that sum to the difference of the average model output for the background dataset and that of the prediction to be explained. \n",
    "\n",
    "In order to get `SHAP` to return the same shapley values we computed above, we can just set the \"background\" dataset to one datapoint of all zeros (\\[0, 0, 0, 0, 0\\]) and set the explanation point to be all ones \\[1, 1, 1, 1, 1\\]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a deeper understanding, the code below is a modified / simplified version of the [shap KernelExplainer code](https://github.com/slundberg/shap/blob/master/shap/explainers/kernel.py).\n",
    "\n",
    "We start by defining three things to implement this on our own:\n",
    "1. The number of samples for the program to take\n",
    "2. The background dataset to compare to the outcome\n",
    "3. The data point to be explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 20\n",
    "explanation_index = 31\n",
    "explanation_data = np.array(observed_data.loc[explanation_index, ~(observed_data.columns.isin([\"value\"]))]).reshape(1, -1)\n",
    "explanation_outcome = np.array(observed_data.loc[explanation_index, \"value\"]).reshape(1, -1)\n",
    "background_index = 0\n",
    "background_data = np.array(observed_data.loc[background_index, ~(observed_data.columns.isin([\"value\"]))]).reshape(1, -1) if np.size(background_index) == 1 else np.array(observed_data.loc[background_index, ~(observed_data.columns.isin([\"value\"]))])\n",
    "background_outcome = np.array(observed_data.loc[background_index, \"value\"]).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract some information from these inputs to make processing easier and construct the \"weights\" needed for weighted least squares regression (used to fit the Shapley values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If someone asks for more samples than either the total number of possible combinations (2^p) or 2^32, \n",
    "# just ignore the rest\n",
    "n = np.shape(background_data)[0]\n",
    "p = np.shape(background_data)[1]\n",
    "if n_samples >= 2**32:\n",
    "    n_samples = 2**32 - 2\n",
    "elif n_samples > 2**p and p < 32:\n",
    "    n_samples = 2**p - 2\n",
    "\n",
    "# Loop through as many combinations of the features as possible\n",
    "synth_data = np.tile(background_data, (n_samples, 1))\n",
    "columns_flipped = np.zeros((n_samples, p))\n",
    "column_nums = np.arange(p)\n",
    "n_subsets = np.int(np.ceil((p-1)/2.0))\n",
    "n_paired_subsets = np.int(np.floor((p-1)/2.0))\n",
    "weight_vector = np.array([(p - 1.0) / (i * (p - i)) for i in range(1, n_subsets + 1)])\n",
    "weight_vector[:n_paired_subsets] *= 2\n",
    "weight_vector /= np.sum(weight_vector)\n",
    "kernelWeights = np.zeros(n_samples)\n",
    "y = np.zeros((n_samples * n, 1))\n",
    "ey = np.zeros((n_samples, 1))\n",
    "data_weights = np.ones(n)\n",
    "data_weights /= np.sum(data_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a synthetic dataset according to the sampling procedure above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for subset_size in range(1, (n_subsets+1)):\n",
    "    # Skip over a set of combinations if there's no room to add them all to the synthetic data\n",
    "    num_combinations = binom(p, subset_size) if subset_size > n_paired_subsets else binom(p, subset_size)*2\n",
    "    if num_combinations <= (n_samples - i):\n",
    "\n",
    "        w = weight_vector[subset_size - 1] / num_combinations\n",
    "        \n",
    "        # Use itertools to run through these combinations\n",
    "        for comb in combinations(column_nums, subset_size):\n",
    "            flip_indicator = np.isin(column_nums, comb)\n",
    "            flip_columns = np.flatnonzero(flip_indicator)\n",
    "            columns_flipped[i, ] = flip_indicator\n",
    "            synth_data[i*n:(i+1)*n, flip_columns] = explanation_data[0, flip_columns]\n",
    "            kernelWeights[i] = w\n",
    "            i += 1\n",
    "            \n",
    "            # If there is a paired subset on the other side of the combinatorial tree (i.e. 6 choose 5 \n",
    "            # instead of 6 choose 1), then sample that as well\n",
    "            if subset_size <= n_paired_subsets:\n",
    "                flip_indicator = ~np.isin(column_nums, comb)\n",
    "                flip_columns = np.flatnonzero(flip_indicator)\n",
    "                columns_flipped[i, ] = flip_indicator\n",
    "                synth_data[i*n:(i+1)*n, flip_columns] = explanation_data[0, flip_columns]\n",
    "                kernelWeights[i] = w\n",
    "                i += 1\n",
    "                \n",
    "    elif i < n_samples:\n",
    "        # Otherwise just take random samples from those combinations to fill up the synth_data set\n",
    "        comb_list = np.random.permutation(list(combinations(column_nums, subset_size)))\n",
    "        remaining_loops = (n_samples - i)//2\n",
    "        w = np.sum(weight_vector[(subset_size-1):])/(n_samples - i)\n",
    "        for j in range(0, remaining_loops):\n",
    "            # Pick a random sample\n",
    "            column_samples = comb_list[j]\n",
    "            flip_indicator = np.isin(column_nums, column_samples)\n",
    "            flip_columns = np.flatnonzero(flip_indicator)\n",
    "            columns_flipped[i, ] = flip_indicator\n",
    "            synth_data[i*n:(i+1)*n, flip_columns] = explanation_data[0, flip_columns]\n",
    "            kernelWeights[i] = w\n",
    "            i += 1\n",
    "\n",
    "            # Then add its paired converse to the sample list as well\n",
    "            flip_indicator = ~np.isin(column_nums, column_samples)\n",
    "            flip_columns = np.flatnonzero(flip_indicator)\n",
    "            columns_flipped[i, ] = flip_indicator\n",
    "            synth_data[i*n:(i+1)*n, flip_columns] = explanation_data[0, flip_columns]\n",
    "            kernelWeights[i] = w\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the expected value of the \"model\" (in this case, it's just a matrix of completely enumerated values) for each of the synthetic data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model on the synthetic data\n",
    "def extract_model_values(matrix_row, df, boolean_matrix):\n",
    "    return df.loc[np.apply_along_axis(row_equality, 1, boolean_matrix, matrix_row), \"value\"].values\n",
    "modelOut = np.apply_along_axis(extract_model_values, 1, synth_data, df = observed_data, boolean_matrix=boolean_matrix).reshape(-1)\n",
    "y = np.reshape(modelOut, (n_samples * n, 1))\n",
    "\n",
    "# Calculate expected value for each synthetic datapoint, making possible use of data weights\n",
    "for i in range(0, n_samples * n):\n",
    "    eyVal = np.zeros(1)\n",
    "    for j in range(0, n):\n",
    "        eyVal += y[i * n + j, :] * data_weights[j]\n",
    "    ey[i, :] = eyVal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate Shapley values by a weighted least squares regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average value of the outcome in the background dataset\n",
    "original_value = np.squeeze(np.sum((background_outcome.T * data_weights).T, 0))\n",
    "# Compute the value of the outcome for the data point we're explaining\n",
    "explanation_value = np.squeeze(explanation_outcome)\n",
    "# Look at the difference between the model estimates for the synthetic dataset and the background average\n",
    "eyAdj = np.squeeze(ey) - original_value\n",
    "\n",
    "# # Note: when there are a lot of features, the SHAP library will do some sort of \n",
    "# regularization here to narrow to a smaller set of features\n",
    "# # Skipping that for simplicity\n",
    "\n",
    "# Only need to estimate values for p-1 columns, since the total sum of Shapley values is \n",
    "# already constrained to be explanation_value - original_value\n",
    "eyAdj2 = eyAdj - columns_flipped[:, column_nums[-1]] * (explanation_value - original_value)\n",
    "etmp = np.transpose(np.transpose(columns_flipped[:, column_nums[:-1]]) - columns_flipped[:, column_nums[-1]])\n",
    "\n",
    "# Estimate shapley values using weighted least squares\n",
    "tmp = np.transpose(np.transpose(etmp) * np.transpose(kernelWeights))\n",
    "tmp2 = np.linalg.inv(np.dot(np.transpose(tmp), etmp))\n",
    "w = np.dot(tmp2, np.dot(np.transpose(tmp), eyAdj2))\n",
    "phi = np.zeros(p)\n",
    "phi[column_nums[:-1]] = w\n",
    "phi[column_nums[-1]] = (explanation_value - original_value) - sum(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at estimated shapley values for that sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average outcome in background dataset: 0.00\n",
      "Outcome for the explanation data point: 240.00\n",
      "Difference in outcomes: 240.00\n",
      "X1 data value: 1.00\n",
      "X1 Shapley value: 100.00\n",
      "X2 data value: 1.00\n",
      "X2 Shapley value: 60.00\n",
      "X3 data value: 1.00\n",
      "X3 Shapley value: 40.00\n",
      "X4 data value: 1.00\n",
      "X4 Shapley value: 30.00\n",
      "X5 data value: 1.00\n",
      "X5 Shapley value: 10.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Average outcome in background dataset: {:.2f}\".format(original_value))\n",
    "print(\"Outcome for the explanation data point: {:.2f}\".format(explanation_value))\n",
    "print(\"Difference in outcomes: {:.2f}\".format(explanation_value-original_value))\n",
    "for player in shap_indices:\n",
    "    print(\"X{:d} data value: {:.2f}\".format(player+1, np.squeeze(explanation_data)[player]))\n",
    "    shap_val = phi[player]\n",
    "    print(\"X{:d} Shapley value: {:.2f}\".format(player+1, shap_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that worked as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "\\[1\\] There are technically a few different \"explainer\" implementations contained within shap (one optimized for trees, one for deep learning, etc...), but the code linked above pertains to the most general (model-agnostic) explanation method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Shapley, L. S. \"A Value for n-Person Games,\" Annals of Math Studies, 28(1953),307-317."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
